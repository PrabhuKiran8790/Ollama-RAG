{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pdf file and split it into smaller chunks\n",
    "loader = PyPDFLoader('./Prabhu Kiran Konda Resume.pdf')\n",
    "documents = loader.load()\n",
    "\n",
    "# Split the documents into smaller chunks \n",
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=30)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modules.json: 100%|██████████| 349/349 [00:00<00:00, 338kB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 268kB/s]\n",
      "README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 9.02MB/s]\n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 310kB/s]\n",
      "config.json: 100%|██████████| 571/571 [00:00<00:00, 3.73MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 438M/438M [00:19<00:00, 22.2MB/s] \n",
      "tokenizer_config.json: 100%|██████████| 363/363 [00:00<00:00, 1.79MB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 4.33MB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 2.72MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 1.05MB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 951kB/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(texts, embeddings)\n",
    "retriever = db.as_retriever(search_kwargs={'k': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm = Ollama(model=\"mistral:7b-instruct-q4_0\", temperature=0, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(llm, retriever,return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 2 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \n",
      "1. AI-SaaS platform with SvelteKit and TailwindCSS, leveraging PostgreSQL for data storage.\n",
      "2. Personal Portfolio + Markdown Blog with SvelteKit, TailwindCSS, TypeScript, and Vercel.\n",
      "3. GFPGAN Image Restoration using Python, Streamlit, Docker, and HuggingFace.\n",
      "4. STLF using Auto Encoders + RBF NN with Python, Tensorflow, Streamlit, and Weights & Biases.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = 'list all the projects mentioned in this resume'\n",
    "result = qa_chain({'question': query, 'chat_history': chat_history})\n",
    "print('Answer: ' + result['answer'] + '\\n')\n",
    "chat_history.append((query, result['answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('list all the publications mentioned in this resume',\n",
       "  '\\n1. A Platform Independent Web-Application for Short-Term Electric Power Load Forecasting on a 33/11 kV Substation Using Regression Model, Advances in Electrical & Electronics Engineering, Paper Link\\n2. Weather Forecasting Using Radial Basis Function Neural Network in Warangal, India, MDPI Urban Science, Paper Link\\n3. Active Power Load Data Dimensionality Reduction Using Autoencoder, Springer, Paper Link'),\n",
       " ('list all the projects mentioned in this resume',\n",
       "  '\\n1. AI-SaaS platform with SvelteKit and TailwindCSS, leveraging PostgreSQL for data storage.\\n2. Personal Portfolio + Markdown Blog with SvelteKit, TailwindCSS, TypeScript, and Vercel.\\n3. GFPGAN Image Restoration using Python, Streamlit, Docker, and HuggingFace.\\n4. STLF using Auto Encoders + RBF NN with Python, Tensorflow, Streamlit, and Weights & Biases.')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
